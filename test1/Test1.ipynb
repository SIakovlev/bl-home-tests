{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup seed for reproducibility\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "tf.random.set_seed(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "train_path = './data/train.csv'\n",
    "df_train = pd.read_csv(train_path, low_memory=False)\n",
    "test_path = './data/test.csv'\n",
    "df_test = pd.read_csv(test_path, low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data in np.array format\n",
    "X, y = df_train.values[:, :-1], df_train.values[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale data to improve convergence (we will use the scaler for the test data as well)\n",
    "train_scaler = StandardScaler().fit(X)\n",
    "X_scaled = train_scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80000, 10) (20000, 10) (80000,) (20000,)\n"
     ]
    }
   ],
   "source": [
    "# split into validation and test datasets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_scaled, y, test_size=0.2)\n",
    "print(X_train.shape, X_val.shape, y_train.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine the number of input features\n",
    "n_features = X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 480.9931 - mse: 480.9931 - val_loss: 71.8002 - val_mse: 71.8002\n",
      "Epoch 2/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 37.7169 - mse: 37.7169 - val_loss: 17.5488 - val_mse: 17.5488\n",
      "Epoch 3/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 9.1504 - mse: 9.1504 - val_loss: 4.4662 - val_mse: 4.4662\n",
      "Epoch 4/50\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 3.5092 - mse: 3.5092 - val_loss: 2.1725 - val_mse: 2.1725\n",
      "Epoch 5/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 2.0373 - mse: 2.0373 - val_loss: 0.7781 - val_mse: 0.7781\n",
      "Epoch 6/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.3273 - mse: 1.3273 - val_loss: 0.9547 - val_mse: 0.9547\n",
      "Epoch 7/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 1.0890 - mse: 1.0890 - val_loss: 0.7996 - val_mse: 0.7996\n",
      "Epoch 8/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.8924 - mse: 0.8924 - val_loss: 0.4001 - val_mse: 0.4001\n",
      "Epoch 9/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.7681 - mse: 0.7681 - val_loss: 0.5944 - val_mse: 0.5944\n",
      "Epoch 10/50\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 0.7028 - mse: 0.7028 - val_loss: 0.3515 - val_mse: 0.3515\n",
      "Epoch 11/50\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 0.6987 - mse: 0.6987 - val_loss: 1.0876 - val_mse: 1.0876\n",
      "Epoch 12/50\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 0.6116 - mse: 0.6116 - val_loss: 0.6809 - val_mse: 0.6809\n",
      "Epoch 13/50\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 0.4716 - mse: 0.4716 - val_loss: 0.1935 - val_mse: 0.1935\n",
      "Epoch 14/50\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 0.4492 - mse: 0.4492 - val_loss: 0.2134 - val_mse: 0.2134\n",
      "Epoch 15/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.5226 - mse: 0.5226 - val_loss: 0.3019 - val_mse: 0.3019\n",
      "Epoch 16/50\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.3556 - mse: 0.3556 - val_loss: 0.1137 - val_mse: 0.1137\n",
      "Epoch 17/50\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.4091 - mse: 0.4091 - val_loss: 0.2895 - val_mse: 0.2895\n",
      "Epoch 18/50\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 0.3744 - mse: 0.3744 - val_loss: 0.3488 - val_mse: 0.3488\n",
      "Epoch 19/50\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 0.3921 - mse: 0.3921 - val_loss: 0.3020 - val_mse: 0.3020\n",
      "Epoch 20/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.3162 - mse: 0.3162 - val_loss: 0.0964 - val_mse: 0.0964\n",
      "Epoch 21/50\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 0.4335 - mse: 0.4335 - val_loss: 0.2447 - val_mse: 0.2447\n",
      "Epoch 22/50\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 0.2586 - mse: 0.2586 - val_loss: 0.1474 - val_mse: 0.1474\n",
      "Epoch 23/50\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 0.3062 - mse: 0.3062 - val_loss: 0.0900 - val_mse: 0.0900\n",
      "Epoch 24/50\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.2771 - mse: 0.2771 - val_loss: 0.2033 - val_mse: 0.2033\n",
      "Epoch 25/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.2857 - mse: 0.2857 - val_loss: 0.1298 - val_mse: 0.1298\n",
      "Epoch 26/50\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 0.3149 - mse: 0.3149 - val_loss: 0.1287 - val_mse: 0.1287\n",
      "Epoch 27/50\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.2803 - mse: 0.2803 - val_loss: 0.1825 - val_mse: 0.1825\n",
      "Epoch 28/50\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.2270 - mse: 0.2270 - val_loss: 0.3004 - val_mse: 0.3004\n",
      "Epoch 29/50\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 0.2985 - mse: 0.2985 - val_loss: 0.1265 - val_mse: 0.1265\n",
      "Epoch 30/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.2616 - mse: 0.2616 - val_loss: 0.0434 - val_mse: 0.0434\n",
      "Epoch 31/50\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 0.2586 - mse: 0.2586 - val_loss: 0.0524 - val_mse: 0.0524\n",
      "Epoch 32/50\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 0.2808 - mse: 0.2808 - val_loss: 0.0505 - val_mse: 0.0505\n",
      "Epoch 33/50\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 0.2537 - mse: 0.2537 - val_loss: 1.4537 - val_mse: 1.4537\n",
      "Epoch 34/50\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 0.2094 - mse: 0.2094 - val_loss: 0.0867 - val_mse: 0.0867\n",
      "Epoch 35/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.2422 - mse: 0.2422 - val_loss: 0.0379 - val_mse: 0.0379\n",
      "Epoch 36/50\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 0.2469 - mse: 0.2469 - val_loss: 0.0959 - val_mse: 0.0959\n",
      "Epoch 37/50\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 0.2374 - mse: 0.2374 - val_loss: 0.0643 - val_mse: 0.0643\n",
      "Epoch 38/50\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 0.2006 - mse: 0.2006 - val_loss: 0.3753 - val_mse: 0.3753\n",
      "Epoch 39/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.2239 - mse: 0.2239 - val_loss: 0.4463 - val_mse: 0.4463\n",
      "Epoch 40/50\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 0.2006 - mse: 0.2006 - val_loss: 0.1274 - val_mse: 0.1274\n",
      "Epoch 41/50\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.2802 - mse: 0.2802 - val_loss: 0.1031 - val_mse: 0.1031\n",
      "Epoch 42/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.1754 - mse: 0.1754 - val_loss: 1.1523 - val_mse: 1.1523\n",
      "Epoch 43/50\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 0.2070 - mse: 0.2070 - val_loss: 0.2513 - val_mse: 0.2513\n",
      "Epoch 44/50\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 0.2229 - mse: 0.2229 - val_loss: 0.1448 - val_mse: 0.1448\n",
      "Epoch 45/50\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 0.2329 - mse: 0.2329 - val_loss: 0.0233 - val_mse: 0.0233\n",
      "Epoch 46/50\n",
      "2500/2500 [==============================] - 4s 1ms/step - loss: 0.2053 - mse: 0.2053 - val_loss: 0.1749 - val_mse: 0.1749\n",
      "Epoch 47/50\n",
      "2500/2500 [==============================] - 3s 1ms/step - loss: 0.2060 - mse: 0.2060 - val_loss: 0.0766 - val_mse: 0.0766\n",
      "Epoch 48/50\n",
      "2500/2500 [==============================] - 5s 2ms/step - loss: 0.1891 - mse: 0.1891 - val_loss: 0.1438 - val_mse: 0.1438\n",
      "Epoch 49/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.1864 - mse: 0.1864 - val_loss: 0.1729 - val_mse: 0.1729\n",
      "Epoch 50/50\n",
      "2500/2500 [==============================] - 4s 2ms/step - loss: 0.1889 - mse: 0.1889 - val_loss: 0.1067 - val_mse: 0.1067\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f14b1ffbfd0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define model\n",
    "model = Sequential()\n",
    "# side note: use He initialisation as recommended for relu: https://arxiv.org/abs/1502.01852\n",
    "model.add(Dense(40, activation='relu', kernel_initializer='he_normal', input_shape=(n_features,)))\n",
    "model.add(Dense(200, activation='relu', kernel_initializer='he_normal'))\n",
    "model.add(Dense(80, activation='relu', kernel_initializer='he_normal'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "# compile the model\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mse'])\n",
    "# fit the model\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32, verbose=1, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = df_test.values\n",
    "X_test_scaled = train_scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[\"Y\"] = y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.to_csv(\"test_with_predictions.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
